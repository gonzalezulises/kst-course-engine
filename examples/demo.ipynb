{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KST Course Engine â€” Demo Notebook\n",
    "\n",
    "This notebook demonstrates the full pipeline:\n",
    "1. Parse a course definition\n",
    "2. Visualize the structure\n",
    "3. Simulate learner assessment\n",
    "4. Run optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kst_core import (\n",
    "    parse_file,\n",
    "    validate_learning_space,\n",
    "    hasse_mermaid,\n",
    "    course_json,\n",
    "    BLIMParameters,\n",
    "    AdaptiveAssessment,\n",
    "    simulate_responses,\n",
    "    LearningModel,\n",
    "    LearningRate,\n",
    "    estimate_item_difficulty,\n",
    "    optimal_teaching_sequence,\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse a Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course = parse_file(\"diamond-lattice.kst.yaml\")\n",
    "print(f\"Course: {course.name}\")\n",
    "print(f\"Items: {len(course.domain)}\")\n",
    "print(f\"States: {len(course.states)}\")\n",
    "print(f\"Prerequisites: {len(course.prerequisite_graph.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = validate_learning_space(course.domain, course.states)\n",
    "print(f\"Valid: {report.is_valid}\")\n",
    "for r in report.results:\n",
    "    status = 'PASS' if r.passed else 'FAIL'\n",
    "    print(f\"  [{status}] {r.property_name}: {r.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Learning Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = course.to_learning_space()\n",
    "paths = ls.learning_paths()\n",
    "print(f\"Total learning paths: {len(paths)}\")\n",
    "for i, path in enumerate(paths):\n",
    "    print(f\"  {i+1}. {' -> '.join(item.id for item in path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize (Mermaid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hasse_mermaid(ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simulate Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "params = BLIMParameters.uniform(course.domain)\n",
    "state_list = sorted(course.states, key=lambda s: (len(s), sorted(s.item_ids)))\n",
    "\n",
    "true_state = state_list[3]  # Pick a state\n",
    "print(f\"True state: {sorted(true_state.item_ids)}\")\n",
    "\n",
    "responses = simulate_responses(true_state, params, rng=rng)\n",
    "print(f\"Responses: {responses}\")\n",
    "\n",
    "session = AdaptiveAssessment.start(course.domain, course.states, params)\n",
    "result = session.run(responses)\n",
    "print(f\"Estimated state: {sorted(result.current_estimate.item_ids)}\")\n",
    "print(f\"Correct: {result.current_estimate == true_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Learning Trajectory Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = LearningRate.uniform(course.domain)\n",
    "model = LearningModel(space=ls, rates=rates)\n",
    "traj = model.simulate_trajectory(rng=rng)\n",
    "print(f\"Trajectory length: {len(traj)}\")\n",
    "for i, state in enumerate(traj):\n",
    "    print(f\"  Step {i}: {sorted(state.item_ids) if state.item_ids else '{}'}\")\n",
    "\n",
    "expected = model.expected_steps()\n",
    "print(f\"\\nExpected steps from empty: {expected[course.domain.empty_state]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item difficulty\n",
    "diff_report = estimate_item_difficulty(course.domain, course.prerequisite_graph)\n",
    "print(\"Item Difficulty (structural):\")\n",
    "for item in diff_report.items:\n",
    "    print(f\"  {item.item_id}: depth={item.structural_depth}, difficulty={item.combined_difficulty:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal teaching sequence\n",
    "plan = optimal_teaching_sequence(ls)\n",
    "print(f\"Optimal Teaching Plan ({plan.total_expected_steps:.0f} steps):\")\n",
    "for i, step in enumerate(plan.steps):\n",
    "    print(f\"  {i+1}. Teach '{step.item_id}' (remaining: {step.expected_remaining:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. JSON Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.loads(course_json(course))['states']['count'], 'states exported')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
